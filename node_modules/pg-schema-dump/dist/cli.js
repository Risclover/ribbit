#!/usr/bin/env node
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __async = (__this, __arguments, generator) => {
  return new Promise((resolve, reject) => {
    var fulfilled = (value) => {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    };
    var rejected = (value) => {
      try {
        step(generator.throw(value));
      } catch (e) {
        reject(e);
      }
    };
    var step = (x) => x.done ? resolve(x.value) : Promise.resolve(x.value).then(fulfilled, rejected);
    step((generator = generator.apply(__this, __arguments)).next());
  });
};

// src/cli.ts
var import_yargs = __toESM(require("yargs"));
var import_helpers = require("yargs/helpers");

// src/index.ts
var import_pg = require("pg");
var import_pg_connection_from_env = require("pg-connection-from-env");

// src/get-tree.ts
var import_pgtui = require("pgtui");
var getTree = (_0) => __async(void 0, [_0], function* ({
  defaultDatabase,
  schemas
}) {
  return (0, import_pgtui.getTreeFromSQL)(yield getSchemaSQL({ defaultDatabase, schemas }));
});

// src/dump-tree.ts
var import_pgtui2 = require("pgtui");
var dumpTree = (_0) => __async(void 0, [_0], function* ({
  defaultDatabase,
  schemas,
  targetDir
}) {
  const tree = yield getTree({ defaultDatabase, schemas });
  yield (0, import_pgtui2.treeToDirectory)(tree, targetDir);
});

// src/dump-sql.ts
var dumpSql = (_0) => __async(void 0, [_0], function* ({
  defaultDatabase,
  schemas
}) {
  return yield getSchemaSQL({
    defaultDatabase,
    schemas
  });
});

// src/index.ts
var import_pgtui3 = require("pgtui");
var alphabetical = (a, b) => {
  if (a.sequence_name < b.sequence_name) {
    return -1;
  }
  if (a.sequence_name > b.sequence_name) {
    return 1;
  }
  return 0;
};
var getTables = (context) => __async(void 0, null, function* () {
  const { client, schemas } = context;
  const { rows } = yield client.query(`
    SELECT tablename, schemaname FROM pg_tables
    WHERE schemaname IN (${schemas.map((s) => `'${s}'`).join(",")});
  `);
  return rows.map((row) => `${row.schemaname}.${row.tablename}`).sort(alphabetical);
});
var getTableDefinition = (tableWithSchema, context) => __async(void 0, null, function* () {
  const { client } = context;
  const [schema, table] = tableWithSchema.split(".");
  const { rows } = yield client.query(
    `
    SELECT *
    FROM INFORMATION_SCHEMA.COLUMNS
    WHERE table_name = $1 AND table_schema = $2;
  `,
    [table, schema]
  );
  return `CREATE TABLE ${schema}.${table} (
    ${rows.map((row) => {
    const dataType = row.data_type.toUpperCase() === "ARRAY" ? `${row.udt_name.replace(/^_/, "")}[]` : row.data_type;
    return `${row.column_name} ${dataType} ${row.is_nullable === "YES" ? "NULL" : "NOT NULL"} DEFAULT ${row.column_default || "NULL"}`;
  }).sort(alphabetical).join(",\n")}
  );
`;
});
var getTableConstraints = (_0, _1) => __async(void 0, [_0, _1], function* ({
  tableWithSchema,
  primaryKeysOnly = false,
  noPrimaryKeys = false
}, context) {
  const { client } = context;
  const [schema, table] = tableWithSchema.split(".");
  const { rows } = yield client.query(
    `
    SELECT conname, pg_get_constraintdef(c.oid)
    FROM pg_constraint c
    JOIN pg_namespace n ON n.oid = c.connamespace
    WHERE conrelid = (SELECT oid FROM pg_class WHERE relname = $1 AND relnamespace = n.oid LIMIT 1)
      AND n.nspname = $2;
  `,
    [table, schema]
  );
  return rows.filter((row) => {
    if (primaryKeysOnly) {
      return row.pg_get_constraintdef.includes("PRIMARY KEY");
    }
    if (noPrimaryKeys) {
      return !row.pg_get_constraintdef.includes("PRIMARY KEY");
    }
    return true;
  }).map(
    (row) => `ALTER TABLE ONLY ${schema}."${table}" ADD CONSTRAINT "${row.conname}" ${row.pg_get_constraintdef};
`
  ).sort(alphabetical).join("");
});
var getFunctions = (context) => __async(void 0, null, function* () {
  const { client, schemas } = context;
  let { rows } = yield client.query(`
    SELECT pg_get_functiondef(f.oid)
    FROM pg_catalog.pg_proc f
    INNER JOIN pg_catalog.pg_namespace n ON (f.pronamespace = n.oid)
    WHERE n.nspname IN (${schemas.map((s) => `'${s}'`).join(",")})
  `);
  rows = rows.filter((r) => !r.pg_get_functiondef.includes("$libdir"));
  return rows.map((row) => `${row.pg_get_functiondef};
`).sort(alphabetical).join("");
});
function recreateTriggerDefinitions(triggerInfos) {
  const groupedTriggers = {};
  triggerInfos.forEach((triggerInfo) => {
    const { trigger_name } = triggerInfo;
    if (groupedTriggers[trigger_name]) {
      groupedTriggers[trigger_name].push(triggerInfo);
    } else {
      groupedTriggers[trigger_name] = [triggerInfo];
    }
  });
  const triggerDefinitions = [];
  for (const triggerName in groupedTriggers) {
    const group = groupedTriggers[triggerName];
    const eventManipulations = group.map((t) => t.event_manipulation).join(" OR ");
    const triggerDefinition = `CREATE TRIGGER ${triggerName} ${group[0].action_timing} ${eventManipulations} ON ${group[0].event_object_schema}.${group[0].event_object_table} FOR EACH ROW ${group[0].action_statement};`;
    triggerDefinitions.push(triggerDefinition);
  }
  return triggerDefinitions;
}
var getTriggers = (context) => __async(void 0, null, function* () {
  const { client, schemas } = context;
  const { rows } = yield client.query(`
    SELECT *
    FROM information_schema.triggers
    WHERE trigger_schema IN (${schemas.map((s) => `'${s}'`).join(",")})
  `);
  return recreateTriggerDefinitions(rows).sort(alphabetical).join("\n");
});
var getExtensions = (context) => __async(void 0, null, function* () {
  const { client } = context;
  const { rows } = yield client.query(`
    SELECT extname FROM pg_extension;
  `);
  return rows.map((row) => `CREATE EXTENSION IF NOT EXISTS ${row.extname};
`).sort(alphabetical).join("");
});
var getIndexes = (tableWithSchema, context) => __async(void 0, null, function* () {
  const { client } = context;
  const [schema, table] = tableWithSchema.split(".");
  const { rows } = yield client.query(
    `
    SELECT indexname, indexdef
    FROM pg_indexes
    WHERE tablename = $1 AND schemaname = $2;
  `,
    [table, schema]
  );
  const { rows: constraints } = yield client.query(
    `
    SELECT conname, pg_get_constraintdef(c.oid)
    FROM pg_constraint c
    JOIN pg_namespace n ON n.oid = c.connamespace
    WHERE conrelid = (SELECT oid FROM pg_class WHERE relname = $1 AND relnamespace = n.oid LIMIT 1) 
      AND n.nspname = $2;
  `,
    [table, schema]
  );
  return rows.filter(
    (row) => !constraints.some(
      (constraint) => constraint.conname === row.indexname
    )
  ).map((row) => `${row.indexdef};
`).sort(alphabetical).join("");
});
var getGrants = (context) => __async(void 0, null, function* () {
  const { client, schemas } = context;
  const { rows } = yield client.query(`
    SELECT grantee, privilege_type, table_name, table_schema
    FROM information_schema.role_table_grants
    WHERE table_schema IN (${schemas.map((s) => `'${s}'`).join(",")});
  `);
  return rows.map(
    (row) => `GRANT ${row.privilege_type} ON ${row.table_schema}.${row.table_name} TO ${row.grantee};
`
  ).sort(alphabetical).join("");
});
var getSchemas = (context) => __async(void 0, null, function* () {
  const { client, schemas } = context;
  const res = yield client.query(
    `
    SELECT schema_name
    FROM information_schema.schemata
    WHERE schema_name = ANY($1)`,
    [schemas]
  );
  return res.rows.filter((row) => row.schema_name !== "public").map((row) => `CREATE SCHEMA ${row.schema_name};
`).sort(alphabetical).join("");
});
var createSequences = (context) => __async(void 0, null, function* () {
  const { client, schemas } = context;
  const { rows } = yield client.query(`
    SELECT sequence_name, sequence_schema
    FROM information_schema.sequences
    WHERE sequence_schema IN (${schemas.map((s) => `'${s}'`).join(",")});
  `);
  return rows.map(
    (row) => `CREATE SEQUENCE ${row.sequence_schema}.${row.sequence_name};
`
  ).sort(alphabetical).join("");
});
var createViews = (context) => __async(void 0, null, function* () {
  const { client, schemas } = context;
  let { rows } = yield client.query(`
    SELECT table_name, view_definition, table_schema
    FROM information_schema.views
    WHERE table_schema IN (${schemas.map((s) => `'${s}'`).join(",")});
  `);
  rows = rows.sort(
    (a, b) => alphabetical(a.table_schema + a.table_name, b.table_schema + b.table_name)
  );
  const viewDependencies = /* @__PURE__ */ new Map();
  rows.forEach((row) => {
    const viewName = `${row.table_schema}.${row.table_name}`;
    const definition = row.view_definition;
    const dependencies = [];
    rows.forEach((depRow) => {
      const depViewName = `${depRow.table_schema}.${depRow.table_name}`;
      if (definition.includes(depViewName)) {
        dependencies.push(depViewName);
      }
    });
    viewDependencies.set(viewName, dependencies);
  });
  const sortedViews = [];
  const visited = /* @__PURE__ */ new Set();
  const visit = (viewName) => {
    if (!visited.has(viewName)) {
      visited.add(viewName);
      const dependencies = viewDependencies.get(viewName);
      if (!dependencies)
        throw new Error("invalid dep- graph issue");
      dependencies.forEach(visit);
      sortedViews.push(viewName);
    }
  };
  [...viewDependencies.keys()].forEach(visit);
  const viewStatements = sortedViews.map((viewName) => {
    const row = rows.find(
      (r) => `${r.table_schema}.${r.table_name}` === viewName
    );
    return `CREATE VIEW ${row.table_schema}.${row.table_name} AS ${row.view_definition}
`;
  });
  return viewStatements.join("");
});
var getSchemaSQL = (..._0) => __async(void 0, [..._0], function* ({
  defaultDatabase = "postgres",
  schemas = ["public"]
} = {}) {
  const client = new import_pg.Client({
    connectionString: (0, import_pg_connection_from_env.getConnectionStringFromEnv)({
      fallbackDefaults: {
        database: defaultDatabase
      }
    })
  });
  yield client.connect();
  const dumperContext = {
    client,
    schemas
  };
  const tables = yield getTables(dumperContext);
  let sql = "";
  const schemaSQL = yield getSchemas(dumperContext);
  sql += schemaSQL;
  const extensions = yield getExtensions(dumperContext);
  sql += extensions;
  const sequences = yield createSequences(dumperContext);
  sql += sequences;
  for (const table of tables) {
    const tableDefinition = yield getTableDefinition(table, dumperContext);
    sql += tableDefinition;
    const tableConstraints = yield getTableConstraints(
      { tableWithSchema: table, primaryKeysOnly: true },
      dumperContext
    );
    sql += tableConstraints;
  }
  for (const table of tables) {
    const tableConstraints = yield getTableConstraints(
      { tableWithSchema: table, noPrimaryKeys: true },
      dumperContext
    );
    sql += tableConstraints;
    const tableIndexes = yield getIndexes(table, dumperContext);
    sql += tableIndexes;
  }
  const views = yield createViews(dumperContext);
  sql += views;
  const functions = yield getFunctions(dumperContext);
  sql += functions;
  const triggers = yield getTriggers(dumperContext);
  sql += triggers;
  const grants = yield getGrants(dumperContext);
  sql += grants;
  yield client.end();
  return sql;
});

// src/cli.ts
var dumpOptionsFn = (yargs2) => {
  return yargs2.option("host", {
    alias: "h",
    type: "string",
    description: "Host of the PostgreSQL server",
    default: "localhost"
  }).option("port", {
    alias: "p",
    type: "number",
    description: "Port of the PostgreSQL server",
    default: 5432
  }).option("user", {
    alias: "U",
    type: "string",
    description: "Username for the PostgreSQL server",
    default: "postgres"
  }).option("password", {
    alias: "W",
    type: "string",
    description: "Password for the PostgreSQL server"
  }).option("database", {
    alias: "d",
    type: "string",
    description: "Database to dump"
  }).option("schemas", {
    alias: "s",
    type: "string",
    description: "Schemas to dump, comma-separated"
  });
};
(0, import_yargs.default)((0, import_helpers.hideBin)(process.argv)).command(
  "dump",
  "Dumps a PostgreSQL database to a SQL file",
  dumpOptionsFn,
  (argv) => __async(exports, null, function* () {
    if (argv.host)
      process.env.POSTGRES_HOST = argv.host;
    if (argv.port)
      process.env.POSTGRES_PORT = argv.port.toString();
    if (argv.user)
      process.env.POSTGRES_USER = argv.user;
    if (argv.password)
      process.env.POSTGRES_PASSWORD = argv.password;
    if (argv.database)
      process.env.POSTGRES_DATABASE = argv.database;
    console.log(
      yield dumpSql({
        schemas: argv.schemas ? argv.schemas.split(",") : ["public"]
      })
    );
  })
).command(
  "dump-tree target-dir",
  "Dumps a PostgreSQL database into a friendly directory structure suitable for code reviews",
  (yargs2) => dumpOptionsFn(
    yargs2.positional("target-dir", {
      type: "string",
      description: "Target directory to dump tree to"
    })
  ),
  (argv) => __async(exports, null, function* () {
    if (argv.host)
      process.env.POSTGRES_HOST = argv.host;
    if (argv.port)
      process.env.POSTGRES_PORT = argv.port.toString();
    if (argv.user)
      process.env.POSTGRES_USER = argv.user;
    if (argv.password)
      process.env.POSTGRES_PASSWORD = argv.password;
    if (argv.database)
      process.env.POSTGRES_DATABASE = argv.database;
    yield dumpTree({
      targetDir: argv["target-dir"],
      schemas: argv.schemas ? argv.schemas.split(",") : ["public"]
    });
  })
).help().alias("help", "h").parse();
